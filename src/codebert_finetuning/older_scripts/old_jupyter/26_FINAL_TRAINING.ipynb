{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    "    PreTrainedModel,\n",
    "    RobertaConfig,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"bug_localiser\")\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../Data/SSTUBS_ENHANCED_23MAR\"\n",
    "dataset = load_dataset(\"json\", data_files={\n",
    "    \"train\": f\"{data_path}/train.json\",\n",
    "    \"validation\": f\"{data_path}/val.json\",\n",
    "    \"test\": f\"{data_path}/test.json\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "special_tokens = {\n",
    "    \"additional_special_tokens\": [\"[CONTEXT]\", \"[SNIPPET]\", \"[COMMIT]\", \"[PARENT]\"]\n",
    "}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "def preprocess(dataset):\n",
    "    return tokenizer(dataset[\"text\"], truncation=True, padding=False)\n",
    "\n",
    "tokenised_dataset = dataset.map(preprocess, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRobertaClassifier(PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.roberta.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "        for name, param in self.roberta.named_parameters():\n",
    "            if \"embeddings\" in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False # freeze all bar embeddings\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, config.num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "model = CustomRobertaClassifier(RobertaConfig.from_pretrained(model_name, num_labels=2)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiEvalTrainer(Trainer):\n",
    "    def __init__(self, *args, eval_datasets=None, **kwargs):\n",
    "        if eval_datasets and len(eval_datasets) > 0:\n",
    "            kwargs[\"eval_dataset\"] = eval_datasets[0]\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.eval_datasets = eval_datasets or []\n",
    "\n",
    "    def _compute_metrics_with_prefix(self, pred, prefix):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            f\"{prefix}_accuracy\": acc,\n",
    "            f\"{prefix}_precision\": precision,\n",
    "            f\"{prefix}_recall\": recall,\n",
    "            f\"{prefix}_f1\": f1,\n",
    "        }\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        if eval_dataset is None and self.eval_datasets:\n",
    "            results = {}\n",
    "            for i, eval_ds in enumerate(self.eval_datasets):\n",
    "                prefix = [\"eval_train_val\", \"eval_val\"][i]\n",
    "                logger.info(f\" Evaluating dataset {i + 1} with prefix '{prefix}'...\")\n",
    "                eval_output = self.predict(eval_ds, ignore_keys=ignore_keys)\n",
    "                metrics = self._compute_metrics_with_prefix(eval_output, prefix)\n",
    "                metrics[f\"{prefix}_loss\"] = eval_output.metrics[\"test_loss\"]\n",
    "                self.log(metrics)\n",
    "                results.update(metrics)\n",
    "            return results\n",
    "        return super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../../FINAL_CODEBERT_FINETUNED\"\n",
    "log_dir = f\"{output_dir}/logs\"\n",
    "\n",
    "tokenised_dataset[\"train_val\"] = tokenised_dataset[\"train\"].shuffle(seed=42).select(range(min(500, len(tokenised_dataset[\"train\"]))))\n",
    "tokenised_dataset[\"validation\"] = tokenised_dataset[\"validation\"].shuffle(seed=42).select(range(min(500, len(tokenised_dataset[\"validation\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir=log_dir,\n",
    "    report_to=\"none\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    max_steps=100000,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_val_f1\",\n",
    "    greater_is_better=True,\n",
    "    disable_tqdm=False,\n",
    "    push_to_hub=False,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MultiEvalTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenised_dataset[\"train\"],\n",
    "    eval_datasets=[tokenised_dataset[\"train_val\"], tokenised_dataset[\"validation\"]],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]  #  stop if no F1 improvement after 5 evals\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 19:18:00,780 - INFO - Training started with early stopping...\n",
      "/home/olan_healy/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/olan_healy/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='100000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    72/100000 00:13 < 5:15:57, 5.27 it/s, Epoch 0.01/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    logger.info(\"Training started with early stopping...\")\n",
    "    trainer.train()\n",
    "finally:\n",
    "    log_path = f\"{output_dir}/final_log.csv\"\n",
    "    pd.DataFrame(trainer.state.log_history).to_csv(log_path, index=False)\n",
    "    logger.info(f\" Logs saved to {log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
